{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af7e0615-2557-4cc3-8cdc-8f8f9bf021a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "from models.cnn import CNN\n",
    "\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec11c1e1-d054-4511-ba14-5974430fd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH_PYTORCH = \"models/fraud_cnn.pt\"\n",
    "MODEL_PATH_TENSORFLOW = \"models/efficientNet.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce854d-0c81-45dd-a118-078ac10232d1",
   "metadata": {},
   "source": [
    "## Create Spark session and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064fd290-9dce-44f9-a3c2-e8e46bb7ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/29 00:10:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"FraudModelInference_Tables\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b680b5-7f9f-4201-a559-387d10663c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "idimage_df = spark.read.option(\"header\", True).csv(\"data/idimage_fixed.csv\")\n",
    "idlabel_df = spark.read.option(\"header\", True).csv(\"data/idlabel.csv\")\n",
    "idmeta_df = spark.read.option(\"header\", True).csv(\"data/idmeta.csv\")  \n",
    "#spark action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5b6c34-390c-4507-9aa7-645e4181e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change isfraud column datatype to Bool\n",
    "idlabel_df = idlabel_df.withColumn(\"isfraud\", col(\"isfraud\").cast(BooleanType()))   #Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaad2b0-0f0d-4a9c-9e90-0004fb3b631d",
   "metadata": {},
   "source": [
    "# Register all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6d2ce2-1321-48c3-a98e-66cf9a486bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/29 00:10:49 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "idimage_df.createOrReplaceTempView(\"idimage\")\n",
    "idlabel_df.createOrReplaceTempView(\"idlabel\")\n",
    "idmeta_df.createOrReplaceTempView(\"idmeta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b43fde8-ce0b-4fda-a8ce-104417af86b8",
   "metadata": {},
   "source": [
    "# Load model from saved weights (CNN(100), EfficientNet (81%))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b87ae0a9-3de8-4f08-93d7-6a8ba1916868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select which model you want to load:\n",
      "1. PyTorch CNN (.pt file)\n",
      "2. Keras Model (.h5 file)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 or 2:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CNN model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"Select which model you want to load:\")\n",
    "print(\"1. PyTorch CNN (.pt file)\")\n",
    "print(\"2. Keras Model (.h5 file)\")\n",
    "\n",
    "model_choice = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "model = None  \n",
    "\n",
    "if model_choice == '1':\n",
    "    try:\n",
    "        model = CNN()\n",
    "        model.load_state_dict(torch.load(MODEL_PATH_PYTORCH, map_location=torch.device('cpu')))\n",
    "        model.eval()\n",
    "        broadcast_model = spark.sparkContext.broadcast(model)\n",
    "        print(\"PyTorch CNN model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PyTorch model: {e}\")\n",
    "        model = None\n",
    "\n",
    "elif model_choice == '2':\n",
    "    try:\n",
    "        model = load_model(MODEL_PATH_KERAS)\n",
    "        print(\"Keras model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Keras model: {e}\")\n",
    "        model = None\n",
    "\n",
    "else:\n",
    "    print(\"Invalid input. Please enter 1 or 2.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56312250-9a57-45bb-8740-9b6767a0a2bd",
   "metadata": {},
   "source": [
    "Function to preprocess imagepath before sending it to model for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9df582c4-abce-482c-9262-3ce02ccd027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(base64_str):\n",
    "    try:\n",
    "        image_data = base64.b64decode(base64_str)\n",
    "        image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "        image = image.resize((128, 128))  \n",
    "        image_array = np.array(image) / 255.0  # Normalize\n",
    "        image_array = np.expand_dims(image_array, axis=0)  # Add batch dim\n",
    "        image_array = image_array.transpose((0, 3, 1, 2)) \n",
    "        image_tensor = torch.from_numpy(image_array).float()\n",
    "        \n",
    "        return image_tensor\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Preprocessing failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18253e2e-2241-4fc0-a7c3-3f0bc99de5cc",
   "metadata": {},
   "source": [
    "DEFINING an REGISTERING UDF in SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c154803b-ccae-4b2c-a64a-5bd836dc1159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fraud_detector(base64_str):\n",
    "#     if model is None:\n",
    "#         print(\"Model not loaded, cannot perform prediction.\")\n",
    "#         return False \n",
    "\n",
    "#     image_tensor = preprocess_image(base64_str)\n",
    "#     if image_tensor is None:\n",
    "#         return False\n",
    "#     try:\n",
    "#         with torch.no_grad():\n",
    "#             prediction = model(image_tensor)\n",
    "        \n",
    "#         return bool(prediction[0][0] > 0.5)  \n",
    "#     except Exception as e:\n",
    "#         print(f\"Prediction failed: {e}\")\n",
    "#         return False\n",
    "\n",
    "\n",
    "@pandas_udf(BooleanType())\n",
    "def cnn_fraud_detector(image_col: pd.Series) -> pd.Series:\n",
    "    mdl = broadcast_model.value\n",
    "    results = []\n",
    "    for base64_str in image_col:\n",
    "        if mdl is None:\n",
    "            results.append(False)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            image_data = base64.b64decode(base64_str)\n",
    "            image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "            image = image.resize((128, 128))\n",
    "            image_array = np.array(image) / 255.0\n",
    "            image_array = np.expand_dims(image_array, axis=0)\n",
    "            image_array = image_array.transpose((0, 3, 1, 2))\n",
    "            image_tensor = torch.from_numpy(image_array).float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = mdl(image_tensor)\n",
    "            results.append(bool(prediction[0][0] > 0.5))\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction failed: {e}\")\n",
    "            results.append(False)\n",
    "\n",
    "    return pd.Series(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46f4eb08-744d-4ff0-930b-6c8e8bfe9226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/29 00:18:28 WARN SimpleFunctionRegistry: The function cnn_fraud_udf replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.udf.UserDefinedFunction at 0x155458899fd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_udf = udf(cnn_fraud_detector)\n",
    "\n",
    "spark.udf.register(\"cnn_fraud_udf\", cnn_fraud_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757b25d-fe44-4ff7-b98a-719fd709e731",
   "metadata": {},
   "source": [
    "# Schema of tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f61fa8-5290-42c2-8b20-41e6acccaa04",
   "metadata": {},
   "source": [
    "idimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7287a335-2d2b-47d3-a37b-357b7026bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- imageData: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idimage_schema = spark.sql(\"\"\"\n",
    "    SELECT * FROM idimage LIMIT 0;\n",
    "\"\"\")\n",
    "\n",
    "idimage_schema.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f9e5a-5df5-4d7e-99ec-b7253714b540",
   "metadata": {},
   "source": [
    "idlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "400380a4-aa1f-4dd2-be63-6756450712db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- isfraud: boolean (nullable = true)\n",
      " |-- fraudpattern: string (nullable = true)\n",
      " |-- srcvalue: string (nullable = true)\n",
      " |-- srcfontstyle: string (nullable = true)\n",
      " |-- srcfontsize: string (nullable = true)\n",
      " |-- srcfontcolor: string (nullable = true)\n",
      " |-- srcbbox: string (nullable = true)\n",
      " |-- desvalue: string (nullable = true)\n",
      " |-- desfontstyle: string (nullable = true)\n",
      " |-- desfontsize: string (nullable = true)\n",
      " |-- desfontcolor: string (nullable = true)\n",
      " |-- desbbox: string (nullable = true)\n",
      " |-- srcname: string (nullable = true)\n",
      " |-- srcregionvalue: string (nullable = true)\n",
      " |-- srcregionfontstyle: string (nullable = true)\n",
      " |-- srcregionfontsize: string (nullable = true)\n",
      " |-- srcregionfontcolor: string (nullable = true)\n",
      " |-- srcregionbbox: string (nullable = true)\n",
      " |-- srcshift: string (nullable = true)\n",
      " |-- desname: string (nullable = true)\n",
      " |-- desregionvalue: string (nullable = true)\n",
      " |-- desregionfontstyle: string (nullable = true)\n",
      " |-- desregionfontsize: string (nullable = true)\n",
      " |-- desregionfontcolor: string (nullable = true)\n",
      " |-- desregionbbox: string (nullable = true)\n",
      " |-- desshift: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idlabel_schema = spark.sql(\"\"\"\n",
    "    SELECT * FROM idlabel LIMIT 0;\n",
    "\"\"\")\n",
    "idlabel_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54aaef-e18d-451b-993d-fb9858129315",
   "metadata": {},
   "source": [
    "idmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7a0af76-6692-459f-be5e-cfc949528381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- birthday: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- ethnicity: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- issue_date: string (nullable = true)\n",
      " |-- expire_date: string (nullable = true)\n",
      " |-- height: string (nullable = true)\n",
      " |-- weight: string (nullable = true)\n",
      " |-- eye_color: string (nullable = true)\n",
      " |-- hair_color: string (nullable = true)\n",
      " |-- is_donor: string (nullable = true)\n",
      " |-- is_veteran: string (nullable = true)\n",
      " |-- license_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idmeta_schema = spark.sql(\"\"\"\n",
    "    SELECT * FROM idmeta LIMIT 0;\n",
    "\"\"\")\n",
    "idmeta_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a708d0-2b25-46b4-b861-8185e855c9ec",
   "metadata": {},
   "source": [
    "# SQL QUEREIS TO GET INSIGHTS FROM DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525426d-a739-41ce-b3b0-f4a675c77ff0",
   "metadata": {},
   "source": [
    "Total IDs and Predicted Fraud Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d008f162-cc4c-4b2d-9c2c-a083345abfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES A LOT OF TIME TO RUN AND MEMORY AS WELL BECAUSE FOR EACH SUM IT RUNS MODEL INFERENCE\n",
    "# spark.sql(\"\"\"\n",
    "# SELECT \n",
    "#     COUNT(*) AS total_ids,\n",
    "#     SUM(CASE WHEN fraud_udf(imageData) THEN 1 ELSE 0 END) AS fraud_predicted,\n",
    "#     (SUM(CASE WHEN fraud_udf(imageData) THEN 1 ELSE 0 END) * 100.0) / COUNT(*) AS fraud_rate_percentage\n",
    "# FROM idimage\n",
    "# \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c5e08-0c9a-40a4-ae28-35e4a010d344",
   "metadata": {},
   "source": [
    "ADDING PREDICTION COLUMN TO THE TABLE FOR FASTER ANSWER RETRiEVAL using UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60234bda-bd5c-4634-81d9-1ca38a614914",
   "metadata": {},
   "outputs": [],
   "source": [
    "idimage_with_pred = idimage_df.withColumn(\n",
    "    \"predicted_fraud\",\n",
    "    cnn_fraud_detector(col(\"imageData\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3622acab-35c5-48d9-97be-28649ab81841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGISTERING THE NEW TEMPORARY VIEW\n",
    "idimage_with_pred.createOrReplaceTempView(\"idimage_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03174ff8-9fdf-46f5-80de-867b912c0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Total IDs and Predicted Fraud Percentage ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 4) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------------------+\n",
      "|total_ids|fraud_predicted|fraud_rate_percentage|\n",
      "+---------+---------------+---------------------+\n",
      "|      998|            199|    19.93987975951904|\n",
      "+---------+---------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"\"\"================ Total IDs and Predicted Fraud Percentage ================\"\"\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) AS total_ids,\n",
    "    SUM(CASE WHEN predicted_fraud THEN 1 ELSE 0 END) AS fraud_predicted,\n",
    "    (SUM(CASE WHEN predicted_fraud THEN 1 ELSE 0 END) * 100.0) / COUNT(*) AS fraud_rate_percentage\n",
    "FROM idimage_pred\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ab040d4-0ae2-4097-9159-4c8479956117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Total Fraudulent vs Non-Fraudulent IDs (Ground Truth) ================\n",
      "+---------+-----------+--------------+------------------+\n",
      "|total_ids|total_fraud|total_nonfraud|  fraud_percentage|\n",
      "+---------+-----------+--------------+------------------+\n",
      "|      199|        199|             0|100.00000000000000|\n",
      "+---------+-----------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\"\"================ Total Fraudulent vs Non-Fraudulent IDs (Ground Truth) ================\"\"\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_ids,\n",
    "        SUM(CASE WHEN isfraud THEN 1 ELSE 0 END) AS total_fraud,\n",
    "        SUM(CASE WHEN NOT isfraud THEN 1 ELSE 0 END) AS total_nonfraud,\n",
    "        (SUM(CASE WHEN isfraud THEN 1 ELSE 0 END) * 100.0) / COUNT(*) AS fraud_percentage\n",
    "    FROM idlabel\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d06716da-2755-4a1b-8658-48ec0e4d71ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Most Common Fraud Patterns ================\n",
      "+--------------------+-------------+\n",
      "|        fraudpattern|pattern_count|\n",
      "+--------------------+-------------+\n",
      "|Fraud6_crop_and_r...|          100|\n",
      "|Fraud5_inpaint_an...|           99|\n",
      "+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\"\"================ Most Common Fraud Patterns ================\"\"\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        fraudpattern, \n",
    "        COUNT(*) AS pattern_count\n",
    "    FROM idlabel\n",
    "    WHERE isfraud = TRUE\n",
    "    GROUP BY fraudpattern\n",
    "    ORDER BY pattern_count DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55071575-6972-4915-87cd-a3ab9899ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving empty table\n",
    "# print(\"\"\"================  Fraud Rate Gender Wise ================\"\"\")\n",
    "# spark.sql(\"\"\"\n",
    "#     SELECT \n",
    "#         m.gender,\n",
    "#         COUNT(*) AS total,\n",
    "#         SUM(CASE WHEN l.isfraud THEN 1 ELSE 0 END) AS fraud_count,\n",
    "#     FROM idmeta m\n",
    "#     JOIN idlabel l ON m.id = l.id\n",
    "#     GROUP BY m.gender\n",
    "#     ORDER BY fraud_rate DESC\n",
    "# \"\"\").show()\n",
    "\n",
    "# +------+-----+-----------+----------+\n",
    "# |gender|total|fraud_count|fraud_rate|\n",
    "# +------+-----+-----------+----------+\n",
    "# +------+-----+-----------+----------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ed225e1-be71-4fd2-8c9b-dcbe20973613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\"\"================  Ground Truth v/s Prediction ================\"\"\")\n",
    "# spark.sql(\"\"\"\n",
    "#     SELECT \n",
    "#         m.id, m.name, l.isfraud, p.predicted_fraud\n",
    "#     FROM idmeta m\n",
    "#     JOIN idlabel l ON m.id = l.id\n",
    "#     JOIN idimage_pred p ON m.name = p.name\n",
    "#     WHERE l.isfraud <> p.predicted_fraud\n",
    "# \"\"\").show()\n",
    "\n",
    "# getting empty output\n",
    "# \"\"\"\n",
    "# +---+----+-------+---------------+\n",
    "# | id|name|isfraud|predicted_fraud|\n",
    "# +---+----+-------+---------------+\n",
    "# +---+----+-------+---------------+\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29982010-9eda-4272-9b53-3bcc56a00d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e806d8-ba57-4abe-8e40-0a298007d820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
